{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d84fc31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02b25530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/connection.py\", line 174, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/util/connection.py\", line 95, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 398, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/connection.py\", line 239, in request\n",
      "    super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n",
      "  File \"/Users/jcheung/.pyenv/versions/3.9.6/lib/python3.9/http/client.py\", line 1257, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/Users/jcheung/.pyenv/versions/3.9.6/lib/python3.9/http/client.py\", line 1303, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/jcheung/.pyenv/versions/3.9.6/lib/python3.9/http/client.py\", line 1252, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/jcheung/.pyenv/versions/3.9.6/lib/python3.9/http/client.py\", line 1012, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/Users/jcheung/.pyenv/versions/3.9.6/lib/python3.9/http/client.py\", line 952, in send\n",
      "    self.connect()\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/connection.py\", line 205, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/connection.py\", line 186, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x1652ead90>: Failed to establish a new connection: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/requests/adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 815, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 815, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 815, in urlopen\n",
      "    return self.urlopen(\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/urllib3/util/retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=5433): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=mnist-hyperparam-optuna-local (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1652ead90>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/mlflow/utils/rest_utils.py\", line 187, in http_request\n",
      "    json_body = json.loads(json_body)\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/mlflow/utils/rest_utils.py\", line 118, in _get_http_response_with_retries\n",
      "    return False\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/requests/sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/requests/sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/requests/adapters.py\", line 565, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=5433): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=mnist-hyperparam-optuna-local (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1652ead90>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/7k/0g6mnyq964z2cp592lvzfn480000gr/T/ipykernel_15626/2976881229.py\", line 22, in <module>\n",
      "    experiment_info = mlflow.set_experiment(experiment_name)\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/mlflow/tracking/fluent.py\", line 114, in set_experiment\n",
      "    Lifecycle_stage: active\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/mlflow/tracking/client.py\", line 461, in get_experiment_by_name\n",
      "    print(\"Name: {}\".format(experiment.name))\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py\", line 220, in get_experiment_by_name\n",
      "    :return: :py:class:`mlflow.entities.Experiment`\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py\", line 304, in get_experiment_by_name\n",
      "    def get_experiment_by_name(self, experiment_name):\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py\", line 56, in _call_endpoint\n",
      "    def _call_endpoint(self, api, json_body):\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/mlflow/utils/rest_utils.py\", line 296, in call_endpoint\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/mlflow/utils/rest_utils.py\", line 205, in http_request\n",
      "mlflow.exceptions.MlflowException: API request to http://localhost:5433/api/2.0/mlflow/experiments/get-by-name failed with exception HTTPConnectionPool(host='localhost', port=5433): Max retries exceeded with url: /api/2.0/mlflow/experiments/get-by-name?experiment_name=mnist-hyperparam-optuna-local (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1652ead90>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/jcheung/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "def set_mlflow_experiment(experiment_name:str):\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    except mlflow.exceptions.MlflowException as e: \n",
    "        if str(e) == f\"Experiment '{experiment_name}' already exists.\":\n",
    "            print(f'Experiment already exists, setting experiment to {experiment_name}')\n",
    "            experiment_info = mlflow.set_experiment(experiment_name)\n",
    "            experiment_id = experiment_info.experiment_id\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "    print(\"---------------------\")\n",
    "    print('Experiment details are:')\n",
    "    print(\"Name: {}\".format(experiment.name))\n",
    "    print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "    print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "    print(\"Creation timestamp: {}\".format(experiment.creation_time))\n",
    "    return experiment_id\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_URI'] = \"postgresql+psycopg2://postgres:mysecretpassword@localhost:5435/mlflowdb\"\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://127.0.0.1:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'jacheung'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = \"mysecretpassword\"\n",
    "experiment_name = \"mnist-hyperparam-optuna-local\"\n",
    "experiment_info = mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32db4af5",
   "metadata": {},
   "source": [
    "## MLFlow\n",
    "MLFLow has 4 different applications: Tracking, Registry, Models, Projects. In this script, we'll demo all 4 via a local environment. \n",
    "1. Tracking: we will log hyper-parameters used and metrics for a transfer-learning model tuned to MNIST.  \n",
    "2. Registry: after our tuned model is identified, we will register our model. \n",
    "3. Models: a stored model must be served to deliver value. Models will be leveraged for inference. \n",
    "4. Projects: DS code is packaged to reproduce runs on any platform/machine via Projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6586651e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mlflow\u001b[39m.\u001b[39mget_tracking_uri()  \n\u001b[1;32m      2\u001b[0m \u001b[39m# mlflow.set_tracking_uri('http://mlflow-server.kubeflow.svc.cluster.local:5000')  \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# mlflow.set_registry_uri('http://minio.kubeflow.svc.cluster.local:9000')  \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlflow' is not defined"
     ]
    }
   ],
   "source": [
    "mlflow.get_tracking_uri()  \n",
    "# mlflow.set_tracking_uri('http://mlflow-server.kubeflow.svc.cluster.local:5000')  \n",
    "# mlflow.set_registry_uri('http://minio.kubeflow.svc.cluster.local:9000')  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "421a36b2",
   "metadata": {},
   "source": [
    "### First we'll build all the functions for our ML pipeline.\n",
    "This'll include functions for data loading, preprocessing, and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9162be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensorflow_dataset(dataset_str: str):\n",
    "    (xy_train, xy_test), ds_info = tfds.load(\n",
    "        dataset_str,\n",
    "        split=['train', 'test'], shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True,\n",
    "    )\n",
    "    return (xy_train, xy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999038d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mnist_tfds(image, label=None):\n",
    "    # reshape and upsample to 3 channel for transfer learning models\n",
    "    # ... for when no channel information is present\n",
    "    if len(image.shape) != 3:\n",
    "        image = np.dstack((image, image, image))\n",
    "    # ... for when channel is only 1 dimension\n",
    "    if image.shape[2] == 1:\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "    # normalize pixel values\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    # resize with pad for mobilenetv2\n",
    "    image = tf.image.resize_with_pad(image, target_height=224, target_width=224)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2aef92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(mlflow.pyfunc.PythonModel):     \n",
    "    def fit(self, xy_tuple_train, xy_tuple_test, hyperparameters):\n",
    "        ## Build model\n",
    "        # class names for mnist hardcoded\n",
    "        class_names = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    \n",
    "        # set layer regularization for DNN\n",
    "        regularizer = tf.keras.regularizers.l1_l2(hyperparameters['l1'], hyperparameters['l2'])\n",
    "\n",
    "        # load in mobilenetv2 weights and instantiate dense classification head \n",
    "        base_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "        layers = [\n",
    "            hub.KerasLayer(\n",
    "                base_model,\n",
    "                input_shape=(224, 224, 3),\n",
    "                trainable=False,\n",
    "                name='mobilenet_embedding'),\n",
    "            tf.keras.layers.Dense(hyperparameters['num_hidden'],\n",
    "                                  kernel_regularizer=regularizer,\n",
    "                                  activation='relu',\n",
    "                                  name='dense_hidden'),\n",
    "            tf.keras.layers.Dense(len(class_names),\n",
    "                                  kernel_regularizer=regularizer,\n",
    "                                  activation='softmax',\n",
    "                                  name='mnist_prob')\n",
    "        ]\n",
    "\n",
    "        self._model = tf.keras.Sequential(layers, name='mnist-classification')\n",
    "\n",
    "        # compile model \n",
    "        self._model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hyperparameters['learning_rate']),\n",
    "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                            from_logits=False),\n",
    "                            metrics=['accuracy'])\n",
    "                      \n",
    "        ## Fit model\n",
    "        # fit model and save history to model store\n",
    "        self._train_history = self._model.fit(xy_tuple_train, epochs=hyperparameters['epochs'], validation_data=xy_tuple_test)\n",
    "        self._model_base = base_model\n",
    "        \n",
    "    def predict(self, context, model_input: np.ndarray) -> np.ndarray:\n",
    "        image, _ = preprocess_mnist_tfds(model_input)\n",
    "        image = tf.reshape(image, [1, 224, 224, 3])\n",
    "        return self._model.predict(image).argmax()\n",
    "\n",
    "\n",
    "                            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d567d8d",
   "metadata": {},
   "source": [
    "### Tracking your model\n",
    "#### MLFlow has two levels for organizing projects:\n",
    "1. At the top level we have \"experiments\". These should be named as \"project-task-version\" (e.g. mnist-classification)\n",
    "2. At the lower level we have \"runs\". A run consists of logging hyperparameters and metrics when models are trained. Multiple runs can be stored within an experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b9ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment already exists, setting experiment to mnist-classification\n",
      "---------------------\n",
      "Experiment details are:\n",
      "Name: mnist-classification\n",
      "Experiment_id: 661060572347012195\n",
      "Artifact Location: file:///Users/jcheung/Documents/GitHub/bookshelf/deployment_demos/mlruns/661060572347012195\n",
      "Tags: {'version': 'v0.1'}\n",
      "Lifecycle_stage: active\n",
      "Creation timestamp: 1684258817271\n"
     ]
    }
   ],
   "source": [
    "# mlflow Tracking requires definition of experiment name AND logged params\n",
    "# Experiment names they should be defined as \"project-task-version\"\n",
    "experiment_name = \"mnist-classification\"\n",
    "\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(\n",
    "        experiment_name,\n",
    "        tags={\"version\": \"v0.1\"},\n",
    "    )\n",
    "except mlflow.exceptions.MlflowException as e: \n",
    "    if str(e) == f\"Experiment '{experiment_name}' already exists.\":\n",
    "        print(f'Experiment already exists, setting experiment to {experiment_name}')\n",
    "        experiment_info = mlflow.set_experiment(experiment_name)\n",
    "        experiment_id = experiment_info.experiment_id\n",
    "\n",
    "experiment = mlflow.get_experiment(experiment_id)\n",
    "print(\"---------------------\")\n",
    "print('Experiment details are:')\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "print(\"Creation timestamp: {}\".format(experiment.creation_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c10969a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess and define batch sizes for tensorflow \n",
    "ds_train, ds_test = load_tensorflow_dataset('mnist')\n",
    "model = MNIST()\n",
    "ds_train = ds_train.map(preprocess_mnist_tfds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_test = ds_test.map(preprocess_mnist_tfds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "74397177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/16 13:58:49 INFO mlflow.types.utils: Unsupported type hint: <class 'numpy.ndarray'>, skipping schema inference\n",
      "2023/05/16 13:58:49 INFO mlflow.types.utils: Unsupported type hint: <class 'numpy.ndarray'>, skipping schema inference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://c175ea1e-cf62-4a4f-ac47-906c7be8bcc1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://c175ea1e-cf62-4a4f-ac47-906c7be8bcc1/assets\n"
     ]
    }
   ],
   "source": [
    "# log a base model \n",
    "hyperparams = {\n",
    "    'learning_rate': 0.01,\n",
    "    'l1': 0.0,\n",
    "    'l2': 0.0, \n",
    "    'num_hidden': 16,\n",
    "    'epochs': 10}\n",
    "\n",
    "# Good practice to explicitly define experiment_id and run_name. \n",
    "# Experiment_id can be extracted from above. \n",
    "# Run name examples (e.g. Linear Regression Default Hyperparams).\n",
    "mlflow_run_name='MNIST Xfer Learning Base'\n",
    "with mlflow.start_run(experiment_id=experiment_id, \n",
    "                      run_name=mlflow_run_name) as run:\n",
    "    # You can set autolog for tensorflow model.\n",
    "    # Note that autolog does not allow logging of any additional params and metrics.\n",
    "    # We'll choose to do manual logging.\n",
    "    # mlflow.tensorflow.autolog()\n",
    "\n",
    "    model.fit(ds_train, ds_test, hyperparams)\n",
    "\n",
    "    # MLFlow Tracking parameters\n",
    "    mlflow.log_params(params=hyperparams)\n",
    "    \n",
    "    # MLFlow Tracking metrics \n",
    "    # Logging metrics for each epoch (housed in dictionary)\n",
    "    training_history = model._train_history.history\n",
    "    for epoch in range(0, hyperparams['epochs']):\n",
    "        insert = {}\n",
    "        for metric, value in training_history.items():\n",
    "            insert[metric] = training_history[metric][epoch]\n",
    "        mlflow.log_metrics(metrics=insert, step=epoch+1)\n",
    "\n",
    "    # MLFlow tracking artifact (e.g. model file)\n",
    "    # this will log the model and all its details under run_id/artifacts\n",
    "    mlflow.pyfunc.log_model(python_model=model,\n",
    "                           artifact_path=\"\")\n",
    "\n",
    "    # Close out MLFlow run to prevent any log contamination.\n",
    "    mlflow.end_run(status='FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b2676a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/jcheung/Documents/GitHub/bookshelf/deployment_demos/mlruns/661060572347012195/32d95e08144a4e4799a1fa13976907f1/artifacts'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_artifact_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53821fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-18 11:41:27,609]\u001b[0m A new study created in memory with name: mnist-classification-test\u001b[0m\n",
      "/var/folders/7k/0g6mnyq964z2cp592lvzfn480000gr/T/ipykernel_87134/187522763.py:56: ExperimentalWarning: MLflowCallback is experimental (supported from v1.4.0). The interface can change in the future.\n",
      "  callbacks=[MLflowCallback(metric_name=\"val_accuracy\")]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Epoch 1/3\n",
      "124/469 [======>.......................] - ETA: 11:44 - loss: 8.4303 - accuracy: 0.3422"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "# hyperparameters search using Optuna\n",
    "# can scale Optuna with Kubernetes https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html\n",
    "def objective(trial): \n",
    "    \"\"\"\n",
    "    Optuna objective function for tuning transfer learning model\n",
    "    \"\"\"\n",
    "    hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.00001, 0.1, log=True),\n",
    "        'l1': trial.suggest_float('l1', 0.0, 0.1),\n",
    "        'l2': trial.suggest_float('l2', 0.0, 0.1),\n",
    "        'num_hidden': trial.suggest_int('num_hidden', 8, 64),\n",
    "        'epochs': trial.suggest_int('epochs', 1, 3)\n",
    "    }\n",
    "\n",
    "    model.fit(ds_train, ds_test, hyperparams)\n",
    "    training_history = model._train_history.history\n",
    "    validation_accuracy = training_history['val_accuracy'][-1]\n",
    "    return validation_accuracy\n",
    "\n",
    "POSTGRES_DB=\"deployment_demos_optuna-db_1\"\n",
    "POSTGRES_USER=\"optuna-user\"\n",
    "POSTGRES_PASSWORD=\"optuna-pass\"\n",
    "\n",
    "optuna_study_name = \"mnist-classification-test\"\n",
    "optuna_storage_url=\"postgresql://{}:{}@localhost:5433/{}\".format(\n",
    "            POSTGRES_USER,\n",
    "            POSTGRES_PASSWORD,\n",
    "            POSTGRES_DB,\n",
    "           )\n",
    "  \n",
    "# try:\n",
    "#     print('loading study...')\n",
    "#     study = optuna.load_study(\n",
    "#         study_name=optuna_study_name,\n",
    "#         storage=optuna_storage_url,\n",
    "#     )\n",
    "    \n",
    "# except KeyError:\n",
    "#     print('no study found. building from scratch...')\n",
    "#     study = optuna.create_study(\n",
    "#         study_name=optuna_study_name,\n",
    "#         storage=optuna_storage_url,\n",
    "#         pruner=optuna.pruners.HyperbandPruner(),\n",
    "#         direction='maximize')\n",
    "\n",
    "study = optuna.create_study(\n",
    "        study_name=optuna_study_name,\n",
    "        pruner=optuna.pruners.HyperbandPruner(),\n",
    "        direction='maximize')\n",
    "\n",
    "study.optimize(objective,\n",
    "               n_trials=8,\n",
    "               n_jobs=2,\n",
    "              callbacks=[MLflowCallback(metric_name=\"val_accuracy\")]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f915bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log the hyper parameter tuned model \n",
    "# No need to set experiment ID if you've set above. \n",
    "# Set a run name here(e.g. Linear Regression Default Hyperparams).\n",
    "mlflow_run_name='MNIST Xfer Learning Hyperparam tuned'\n",
    "with mlflow.start_run(experiment_id=experiment_id, \n",
    "                      run_name=mlflow_run_name) as run:\n",
    "    \n",
    "    model.train(ds_train, ds_test, hyperparams)\n",
    "\n",
    "    # MLFlow Tracking parameters\n",
    "    mlflow.log_params(params=hyperparams)\n",
    "    \n",
    "    # MLFlow Tracking metrics \n",
    "    # Logging metrics for each epoch (housed in dictionary)\n",
    "    training_history = model._train_history.history\n",
    "    for epoch in range(0, hyperparams['epochs']):\n",
    "        insert = {}\n",
    "        for metric, value in training_history.items():\n",
    "            insert[metric] = training_history[metric][epoch]\n",
    "        mlflow.log_metrics(metrics=insert, step=epoch+1)\n",
    "\n",
    "    # MLFlow tracking artifact (e.g. model file)\n",
    "    # mlflow.log_artifact(self._model)\n",
    "\n",
    "    # we need to define how we use tags for testing or if we even need them...\n",
    "    mlflow.set_tag(key=\"test\",\n",
    "                   value=\"manual-logging\")\n",
    "\n",
    "    mlflow.end_run(status='FINISHED')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54fe297d",
   "metadata": {},
   "source": [
    "### Registering your model\n",
    "Once you've run a couple experiments (e.g. hyper parameter tuning) we can select the best model and register that. Model registering just means that we decide this our optimized model to save. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "507ec055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search runs \n",
    "filtering_clause = 'params.epochs = \"10\" and params.learning_rate = \"0.01\"'\n",
    "run = mlflow.search_runs(\n",
    "    experiment_names=['mnist-classification'],\n",
    "    filter_string=filtering_clause,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.val_accuracy DESC\"],\n",
    ")\n",
    "\n",
    "# best performing model run_id. This'll be used to register our model\n",
    "best_run_id = run['run_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6987f1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6970ace0f7764536a6125e05008c130e'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4c2a8f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'mnist-classification' already exists. Creating a new version of this model...\n",
      "2023/05/16 14:00:04 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: mnist-classification, version 2\n",
      "Created version '2' of model 'mnist-classification'.\n"
     ]
    }
   ],
   "source": [
    "# register model after a scanning a couple different runs from your experiment \n",
    "model_name = f'{experiment.name}'\n",
    "# mlflow.tensorflow.log_model\n",
    "mv = mlflow.register_model(model_uri=f\"runs:/{best_run_id}/\",\n",
    "                           name=model_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b5c3143",
   "metadata": {},
   "source": [
    "### Serving model\n",
    "After we've registered our model, we can now test inference for that model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b9493c05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load directly from registry \n",
    "# model_version=1\n",
    "# model_name = f'{experiment.name}'\n",
    "# model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
    "\n",
    "# load using artifact path directory\n",
    "results = mlflow.search_registered_models(filter_string='name = \"mnist-classification\"')\n",
    "latest_model_details = results[0].latest_versions[0]\n",
    "model = mlflow.pyfunc.load_model(model_uri=f'{latest_model_details.source[7:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "10ed6ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "True:6 and predicted:6\n"
     ]
    }
   ],
   "source": [
    "# randomly sample and load a MNIST JPEG\n",
    "import os \n",
    "from random import sample\n",
    "from PIL import Image\n",
    "fp = '/Users/jcheung/Documents/GitHub/thin-ML-deployment/app/ml/test_images'\n",
    "files = [f'{fp}/{x}' for x in os.listdir(fp) if x.split('.')[-1] == 'jpg']\n",
    "filename = sample(files, 1)[0]\n",
    "image = np.array(Image.open(filename))\n",
    "\n",
    "# predict using custom mlflow model\n",
    "predicted = model.predict(image)\n",
    "\n",
    "# output and compare results\n",
    "true = filename.split('/')[-1].split('_')[-1][0]\n",
    "\n",
    "print(f'True:{true} and predicted:{predicted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b1e10b3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BatchDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/mlflow/pyfunc/__init__.py:427\u001b[0m, in \u001b[0;36mPyFuncModel.predict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _MLFLOW_OPENAI_TESTING\u001b[38;5;241m.\u001b[39mget():\n\u001b[1;32m    425\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/thick-ML-deployment/lib/python3.9/site-packages/mlflow/pyfunc/model.py:365\u001b[0m, in \u001b[0;36m_PythonModelPyfuncWrapper.predict\u001b[0;34m(self, model_input)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_input):\n\u001b[0;32m--> 365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[84], line 42\u001b[0m, in \u001b[0;36mMNIST.predict\u001b[0;34m(self, context, model_input)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, context, model_input: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m---> 42\u001b[0m     image, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_mnist_tfds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(image, [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mpredict(image)\u001b[38;5;241m.\u001b[39margmax()\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m, in \u001b[0;36mpreprocess_mnist_tfds\u001b[0;34m(image, label)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_mnist_tfds\u001b[39m(image, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# reshape and upsample to 3 channel for transfer learning models\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# ... for when no channel information is present\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m      5\u001b[0m         image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdstack((image, image, image))\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# ... for when channel is only 1 dimension\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61cd631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe83d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kubeflow.katib as katib\n",
    "\n",
    "# Step 1. Create an objective function.\n",
    "def objective(hyperparams):\n",
    "    training_history = model.train(ds_train, ds_test, hyperparams)\n",
    "    validation_accuracy = training_history.history['val_accuracy'][-1]\n",
    "    # Katib parses metrics in this format: <metric-name>=<metric-value>.\n",
    "    print(f\"result={result}\")\n",
    "\n",
    "# Step 2. Create HyperParameter search space.\n",
    "hyperparams = {\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.00001, 0.1, log=True),\n",
    "    'l1': trial.suggest_float('l1', 0.0, 1),\n",
    "    'l2': trial.suggest_float('l2', 0.0, 1),\n",
    "    'num_hidden': katib.search.int(min=8, max=64),\n",
    "    'epochs': katib.search.int(min=5, max=10)\n",
    "}\n",
    "\n",
    "hyperparams = {\n",
    "    \"a\": katib.search.int(min=10, max=20),\n",
    "    \"b\": katib.search.double(min=0.1, max=0.2)\n",
    "}\n",
    "\n",
    "# Step 3. Create Katib Experiment.\n",
    "katib_client = katib.KatibClient()\n",
    "name = \"tune-experiment\"\n",
    "katib_client.tune(\n",
    "    name=name,\n",
    "    objective=objective,\n",
    "    parameters=parameters,\n",
    "    objective_metric_name=\"result\",\n",
    "    max_trial_count=12\n",
    ")\n",
    "\n",
    "# Step 4. Get the best HyperParameters.\n",
    "print(katib_client.get_optimal_hyperparameters(name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thick-ML-deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
